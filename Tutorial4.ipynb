{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TUTORIAL 4 - SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from sklearn import datasets\n",
    "\n",
    "from scipy import interp\n",
    "from itertools import cycle\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer, fetch_openml\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, label_binarize, Normalizer\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve, f1_score, auc, roc_auc_score, average_precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### W tym tutorialu omówiony został jeden z popularniejszych klasyfikatorów, czyli Support Vector Machine. \n",
    "#### SVM może być użyty w zadaniach regresji, jak i klasyfikacji. Głównym jego celem w klasyfikacji jest oddzielenie punktów należących do różnych klas przy użyciu N-wymiarowej hiperpłaszczyzny (N - liczba cech). Taka hiperpłaszczyzna może być wybrana na wiele różnych sposobów, natomiast SVM wybiera taką, dla której odległości między punktami nalezącymi do danej klasy są największe (tzw. maximum margin). Wyznaczona hiperpłaszczyzna jest granicą decyzyjną (decision boundary). \n",
    "#### Czym właściwie są support vectors? -> Są to punkty znajdujące się najbliżej hiperpłaszczyzny i to właśnie przy ich pomocy maksymalizujemy wspomniany wyżej margines. \n",
    "#### Warto zauważyć, że nasza hiperpłaszczyzna zależy od ilości cech, tj. dla 2 cech będzie linią, dla 3 cech będzie dwuwymiarową płaszczyzną itd. A co jeżeli klas nie da się rozdzielić hiperpłaszczyzną w N wymiarach? Wtedy do akcji wkracza tzw Kernel Trick omówiony w dalszej części\n",
    "\n",
    "#### Słowem wstępu, warto również wyjaśnić czym właściwie jest liniowy klasyfikator. Klasyfikator liniowy charakteryzuje się tym, iż dokonuje klasyfikacji na podstawie kombinacji liniowej pewnych charakterystyk. Zatem np problem podziału danych na 2 klasy rozwiązują z wykorzystaniem linii, na 3 klasy z pomocą płaszczyzn w przypadku większej ilości klas używa wspomnianych hiperprzestrzeni.\n",
    "\n",
    "#### W tutorialu wielokrotnie będzie obliczana wartość metryki F1, jej definicja to: F1 = (2 * precision * recall) / (precision + recall), osiąga największą wartość 1 dla idealnej precyzji oraz recall-u.\n",
    "#### Inną obliczaną wartością jest ROC, przedstawia zależność True Positive Rate oraz False Positive Rate, zatem krzywa ROC dla dobrego klasyfikatora powinna mieć wypukły kształt i duże pole pod powierzchnią (area under curve - auc)\n",
    "#### Zanim przejdziemy do realizacji zadań przypomnijmy, czym jest precision, a czym recall: \n",
    "#### Precision = True positive/ (True positive + False positive)\n",
    "#### Recall = True positive/ (True positive + False negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importujemy zbiór iris\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Binaryzacja wyjścia\n",
    "y = label_binarize(y, classes=[0, 1, 2])\n",
    "n_classes = y.shape[1]\n",
    "\n",
    "# Dodanie losowych szumów do danych wejściowych\n",
    "random_state = np.random.RandomState(0)\n",
    "n_samples, n_features = X.shape\n",
    "X = np.c_[X, random_state.randn(n_samples, 200 * n_features)]\n",
    "\n",
    "# Podział zbiorów na treningowy i testowy\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.5, random_state=0)\n",
    "\n",
    "# Trenowanie klasyfikatora\n",
    "classifier_linear = OneVsRestClassifier(LinearSVC(random_state=random_state))\n",
    "classifier_SVM = OneVsRestClassifier(SVC(kernel='linear', probability=True, random_state=random_state))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KERNEL TRICK - zmiana wymiarowości problemu na więcej wymiarów. Czasami dostajemy zbiory danych, których nie da się jasno sklasyfikować np. w 2 wymiarach (np. podzielić zbiór danych funkcjami liniowymi), ale w 3 wymiarach (podział płaszczyznami jest już możliwy). Wtedy rozszerza się problem na 3 wymiary lub więcej. Funkcje przekształcające tego rodzaju problemy na problemy więcej wymiarowe noszą nazwę kernel functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_roc(y_score):\n",
    "# Obliczenie krzywej ROC i obszaru ROC dla każdej z klas\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Obliczanie micro-average krzywej ROC i pola pod krzywą ROC\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "# Wykres krzywej ROC \n",
    "    plt.figure()\n",
    "    plt.plot(fpr[\"micro\"], tpr[\"micro\"], color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc[\"micro\"])\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    print(\"Pole pod wykresem krzywej ROC z micro-average: {0:0.2f}\".format(roc_auc[\"micro\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_precision_and_recall(y_score):\n",
    "    # Dla każdej z klas liczymy precision i recall\n",
    "    precision = dict()\n",
    "    recall = dict()\n",
    "    average_precision = dict()\n",
    "    area_under_curve = dict()\n",
    "    for i in range(n_classes):\n",
    "        precision[i], recall[i], _ = precision_recall_curve(y_test[:, i], y_score[:, i])\n",
    "        average_precision[i] = average_precision_score(y_test[:, i], y_score[:, i])\n",
    "\n",
    "    # Liczymy micro-average precision i recall oraz pole pod wykresem z obliczonych wcześniej klas\n",
    "    precision[\"micro\"], recall[\"micro\"], _ = precision_recall_curve(y_test.ravel(), y_score.ravel())\n",
    "    average_precision[\"micro\"] = average_precision_score(y_test, y_score,average=\"micro\")\n",
    "    area_under_curve = auc(recall[\"micro\"], precision[\"micro\"])\n",
    "    plt.figure()\n",
    "    plt.step(recall['micro'], precision['micro'], where='post')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    print(\"Średnia wartość precision: {0:0.2f}\".format(average_precision[\"micro\"]))\n",
    "    print(\"Średnia wartość pola pod wykresem precision-recall: {0:0.2f}\".format(area_under_curve))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_kernel = OneVsRestClassifier(SVC(kernel='poly', degree=3, probability=True, random_state=random_state))\n",
    "classifiers = [classifier_linear, classifier_SVM, classifier_kernel]\n",
    "y_scores = []\n",
    "for classifier in classifiers:\n",
    "    y_scores.append(classifier.fit(X_train, y_train).decision_function(X_test))\n",
    "\n",
    "\n",
    "for y_score in y_scores:\n",
    "    count_roc(y_score)\n",
    "    count_precision_and_recall(y_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### W zadaniu 1 wyjaśniono, czym jest kernel trick. Wiadomo, że w tym celu mogą być użyte różne funkcje, między innymi takie jak: sigmoid (często używana, jako funkcja aktywacyjna w sieciach neuronowych), radial basis function, czy też polynomial kernel. Przykładowe kernele wspierane przez SVC z biblioteki sklearn to ‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’, domyślnym jest ‘rbf’.\n",
    "#### Teraz dla różnych kerneli porównamy krzywe ROC i PR a także miary F-1 oraz powierzchni pod nimi.\n",
    "\n",
    "#### Wyjaśnijmy jeszcze różnicę między ROC i PR:\n",
    "##### ROC podsumowuje trade-off pomiędzy \"true positive rate\" oraz \"false positive rate\"\n",
    "##### Precision-Recall podsumowuje the trade-off pomiędzy \"true positive rate\" oraz \"positive predictive value\" \n",
    "##### ROC jest istotne, gdy obserwacje pomiędzy klasami są zbalansowane, natomiast precision-recall jest odpowiednie dla niezbalansowanych zbiorów danych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "wbc = load_breast_cancer()\n",
    "wbc_data = wbc.data[:200]\n",
    "wbc_target = wbc.target[:200]\n",
    "\n",
    "kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "cv = StratifiedKFold(n_splits=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classfier(clf, cv, X, Y, precs, recs, fprs, tprs):\n",
    "    mean_auc = 0\n",
    "    mean_auc_pr = 0\n",
    "    f1_mean = 0\n",
    "    for i, (train, test) in enumerate(cv.split(X, Y)):\n",
    "        model = clf.fit(X[train], Y[train])\n",
    "        yproba = model.predict_proba(X[test])[::,1]\n",
    "        pred = model.predict(X[test])\n",
    "        f1 = f1_score(Y[test], pred)\n",
    "        f1_mean += f1\n",
    "\n",
    "        fpr, tpr,_ = roc_curve(Y[test],  yproba)\n",
    "        fprs.append(fpr)\n",
    "        tprs.append(tpr)\n",
    "        curr_auc = roc_auc_score(Y[test],  yproba)\n",
    "        mean_auc += curr_auc\n",
    "\n",
    "        prec, rec, _ = precision_recall_curve(Y[test],  yproba)\n",
    "        precs.append(prec)\n",
    "        recs.append(rec)\n",
    "        curr_auc = auc(rec,prec)\n",
    "        mean_auc_pr += curr_auc\n",
    "    return mean_auc_pr, mean_auc, f1_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ROC(fprs, tprs):\n",
    "    for i in range(len(fprs)):\n",
    "        plt.plot(fprs[i], tprs[i])\n",
    "    plt.xlabel(\"False Positive Rate\", fontsize=15)\n",
    "    plt.ylabel(\"True Positive Rate\", fontsize=15)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_PR(precs, recs):\n",
    "    for i in range(len(precs)):\n",
    "        plt.plot(precs[i], recs[i])\n",
    "    plt.xlabel(\"Recall\", fontsize=15)\n",
    "    plt.ylabel(\"Precision\", fontsize=15)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_per_kernel = {}\n",
    "\n",
    "for k_func in kernels:\n",
    "    print(\"***** {} kernel *****\\n\\n\".format(k_func))\n",
    "    clf = SVC(kernel=k_func, probability=True)\n",
    "    fprs = []\n",
    "    tprs = []\n",
    "    precs = []\n",
    "    recs = []  \n",
    "    mean_auc_pr, mean_auc, f1_mean = train_classfier(clf, cv, wbc_data, wbc_target, precs, recs, fprs, tprs)\n",
    "        \n",
    "    # plot ROC:\n",
    "    plot_ROC(fprs, tprs)\n",
    "  \n",
    "    # plot Precision-Recall:\n",
    "    plot_PR(precs, recs)\n",
    "  \n",
    "    # mean values of auc and f1\n",
    "    print(\"Średnia wartość pola pod krzywą ROC: \", mean_auc/k)\n",
    "    print(\"Średnia wartość pola pod krzywą PR: \", mean_auc_pr/k)\n",
    "    print(\"Średnie F1: \", f1_mean/k)\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### zadanie 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### W tym zadaniu użyjemy GridSearch-a. Przy pomocy tej klasy znajdziemy klasyfikator sparametryzowany tak aby uzyskać najlepsze dopasowanie. Następnie zwizualizujemy wyniki przy pomocy PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_visualization(data, labels, color_map):\n",
    "    df = pd.DataFrame(data) \n",
    "    normalizer = Normalizer()\n",
    "    normalizer.fit(df)\n",
    "    \n",
    "    scaled_data = normalizer.transform(df)\n",
    "    \n",
    "    pca = PCA(n_components=2)\n",
    "    pca.fit(scaled_data)\n",
    "    \n",
    "    x_pca = pca.transform(scaled_data)\n",
    "    colors = np.array([color_map[x] for x in labels])\n",
    "    \n",
    "    plt.figure(figsize=(12, 9))\n",
    "    plt.scatter(x_pca[:, 0], x_pca[:, 1], c=colors, cmap='prism')\n",
    "    patches = list(map(lambda dig_col: mpatches.Patch(color=dig_col[1], label=dig_col[0]), color_map.items()))\n",
    "    plt.legend(handles=patches)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(wbc_data, wbc_target, train_size=.8, random_state=0)\n",
    "\n",
    "clsf = GridSearchCV(SVC(), {'kernel': kernels}, cv=k)\n",
    "clsf.fit(X_train,Y_train)\n",
    "estimator = clsf.best_estimator_\n",
    "print(clsf.best_params_)\n",
    "pred = estimator.predict(X_test)\n",
    "\n",
    "wbc_color_map = {\n",
    "    0 : 'tab:green',\n",
    "    1 : 'tab:red'\n",
    "}\n",
    "print(Y_test)\n",
    "PCA_visualization(X_test, pred, wbc_color_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ZADANIE DO WYKONANIA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Na zbiorze MNIST dokonaj klasyfikacji metodą SVN dla różnych kerneli ('linear', 'poly', 'rbf') oraz metodą k-NN dla k=1,3,5. Dokonaj wizualizacji otrzymanych wyników klasyfikacji przy pomocy PCA. Skomentuj otrzymane wyniki."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ładujemy zbiór danych\n",
    "mnist = fetch_openml(\"mnist_784\", data_home=\"./mnist_784\", cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# podział zbioru na dane treningowe i testowe\n",
    "n_samples = 1500\n",
    "mnist_data = mnist.data[:n_samples]\n",
    "mnist_target = mnist.target[:n_samples]\n",
    "mnist_train_data, mnist_test_data, mnist_train_labels, mnist_test_labels = train_test_split(mnist_data, mnist_target, train_size=0.75, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skorzystaj z tych kolorów w funkcji PCA_visualization()\n",
    "mnist_color_map = {\n",
    "    '0' : 'tab:blue',\n",
    "    '1' : 'tab:orange',\n",
    "    '2' : 'tab:green',\n",
    "    '3' : 'tab:red',\n",
    "    '4' : 'tab:purple',\n",
    "    '5' : 'tab:brown',\n",
    "    '6' : 'tab:pink',\n",
    "    '7' : 'tab:gray',\n",
    "    '8' : 'tab:olive',\n",
    "    '9' : 'tab:cyan',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_classifier_mnist(classifier):\n",
    "    #todo\n",
    "    # train classifier\n",
    "    \n",
    "    # print its score with test data\n",
    "    \n",
    "    # visualize predictions on test data using PCA_visualization()\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Without PCA')\n",
    "print('SVM kernel: linear')\n",
    "classifier = # todo\n",
    "test_classifier_mnist(classifier)\n",
    "\n",
    "# wskazówka: poeksperymentuj z parametrem gamma dla nieliniowych kerneli\n",
    "print('SVM kernel: polynomial')\n",
    "classifier = # todo\n",
    "test_classifier_mnist(classifier)\n",
    "\n",
    "print('SVM kernel: rbf')\n",
    "classifier = # todo\n",
    "test_classifier_mnist(classifier)\n",
    "\n",
    "print('k-NN k=1')\n",
    "classifier = # todo\n",
    "test_classifier_mnist(classifier)\n",
    "\n",
    "print('k-NN k=3')\n",
    "classifier = # todo\n",
    "test_classifier_mnist(classifier)\n",
    "\n",
    "print('k-NN k=5')\n",
    "classifier = # todo\n",
    "test_classifier_mnist(classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wniosek: #todo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dokonaj klasyfikacji ponownie, ale tym razem zredukuj liczbę wymiarów do 30 przy użyciu PCA. Skomentuj otrzymane wyniki (czy uległy poprawie i dlaczego)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_classifier_mnist_pca(classifier):\n",
    "    #todo\n",
    "    # train PCA with train data\n",
    "    \n",
    "    # train classifier with transformed data\n",
    "    \n",
    "    # print its score with transformed test data\n",
    "    \n",
    "    # visualize predictions on test data using PCA_visualization()\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('With PCA')\n",
    "print('SVM kernel: linear')\n",
    "classifier = #todo\n",
    "test_classifier_mnist_pca(classifier)\n",
    "\n",
    "print('SVM kernel: polynomial')\n",
    "classifier = #todo\n",
    "test_classifier_mnist_pca(classifier)\n",
    "\n",
    "print('SVM kernel: rbf')\n",
    "classifier = #todo\n",
    "test_classifier_mnist_pca(classifier)\n",
    "\n",
    "print('k-NN k=1')\n",
    "classifier = #todo\n",
    "test_classifier_mnist_pca(classifier)\n",
    "\n",
    "print('k-NN k=3')\n",
    "classifier = #todo\n",
    "test_classifier_mnist_pca(classifier)\n",
    "\n",
    "print('k-NN k=5')\n",
    "classifier = #todo\n",
    "test_classifier_mnist_pca(classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wniosek: #todo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
